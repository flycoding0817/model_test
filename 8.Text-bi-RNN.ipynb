{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/chinahadoop.png)\n",
    "# 双向LSTM神经网络文本分类\n",
    "**[小象学院](http://www.chinahadoop.cn/course/landpage/15)《机器学习集训营》课程资料 by [@寒小阳](http://www.chinahadoop.cn/user/49339/about)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原理讲解\n",
    "TextBiRNN 是基于 TextRNN 的改进版本，将网络结构中的 RNN 层改进成了双向（Bidirectional）的 RNN 层，希望不仅能考虑正向编码的信息，也能考虑反向编码的信息。\n",
    "### 网络结构\n",
    "\n",
    "<p align=\"center\">\n",
    "\t<img src=\"img/bi-LSTM.png\">\n",
    "</p>\n",
    "\n",
    "### 本文实现\n",
    "\n",
    "<p align=\"center\">\n",
    "\t<img src=\"img/TextBiRNN_network_structure.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout, Bidirectional, LSTM\n",
    "\n",
    "\n",
    "class TextBiRNN(object):\n",
    "    def __init__(self, maxlen, max_features, embedding_dims,\n",
    "                 class_num=5,\n",
    "                 last_activation='softmax'):\n",
    "        self.maxlen = maxlen\n",
    "        self.max_features = max_features\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.class_num = class_num\n",
    "        self.last_activation = last_activation\n",
    "\n",
    "    def get_model(self):\n",
    "        input = Input((self.maxlen,))\n",
    "\n",
    "        embedding = Embedding(self.max_features, self.embedding_dims, input_length=self.maxlen)(input)\n",
    "        #x = Bidirectional(CuDNNLSTM(128))(embedding)\n",
    "        x = Bidirectional(LSTM(128))(embedding)\n",
    "\n",
    "        output = Dense(self.class_num, activation=self.last_activation)(x)\n",
    "        model = Model(inputs=input, outputs=output)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据预处理与加载数据...\n",
      "对序列做padding，保证是 samples*timestep 的维度\n",
      "x_train shape: (65810, 400)\n",
      "x_test shape: (21937, 400)\n",
      "构建模型...\n",
      "Train...\n",
      "Train on 65810 samples, validate on 21937 samples\n",
      "Epoch 1/10\n",
      " 3616/65810 [>.............................] - ETA: 15:27 - loss: 1.4714 - accuracy: 0.3512"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from utils import *\n",
    "\n",
    "# 路径等配置\n",
    "data_dir = \"./processed_data\"\n",
    "vocab_file = \"./vocab/vocab.txt\"\n",
    "vocab_size = 40000\n",
    "\n",
    "# 神经网络配置\n",
    "max_features = 40001\n",
    "maxlen = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "epochs = 10\n",
    "\n",
    "print('数据预处理与加载数据...')\n",
    "# 如果不存在词汇表，重建\n",
    "if not os.path.exists(vocab_file):  \n",
    "    build_vocab(data_dir, vocab_file, vocab_size)\n",
    "# 获得 词汇/类别 与id映射字典\n",
    "categories, cat_to_id = read_category()\n",
    "words, word_to_id = read_vocab(vocab_file)\n",
    "\n",
    "# 全部数据\n",
    "x, y = read_files(data_dir)\n",
    "data = list(zip(x,y))\n",
    "del x,y\n",
    "# 乱序\n",
    "random.shuffle(data)\n",
    "# 切分训练集和测试集\n",
    "train_data, test_data = train_test_split(data)\n",
    "# 对文本的词id和类别id进行编码\n",
    "x_train = encode_sentences([content[0] for content in train_data], word_to_id)\n",
    "y_train = to_categorical(encode_cate([content[1] for content in train_data], cat_to_id))\n",
    "x_test = encode_sentences([content[0] for content in test_data], word_to_id)\n",
    "y_test = to_categorical(encode_cate([content[1] for content in test_data], cat_to_id))\n",
    "\n",
    "print('对序列做padding，保证是 samples*timestep 的维度')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('构建模型...')\n",
    "model = TextBiRNN(maxlen, max_features, embedding_dims).get_model()\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=2, mode='max')\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "print('Test...')\n",
    "result = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "%matplotlib inline\n",
    "\n",
    "fig1 = plt.figure()\n",
    "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves :CNN',fontsize=16)\n",
    "fig1.savefig('loss_cnn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2=plt.figure()\n",
    "plt.plot(history.history['accuracy'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_accuracy'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves : CNN',fontsize=16)\n",
    "fig2.savefig('accuracy_cnn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
